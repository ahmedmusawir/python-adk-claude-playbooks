# GHL API RAG Chatbot â€” Architecture

## What This Is

A complete **docs-site-to-chatbot pipeline** for the GoHighLevel (GHL) API documentation. Given a documentation website, this repo crawls every page, structures the content, uploads it to Google's managed RAG (File Search API), and provides a production-ready chatbot UI to query it.

This is the **first domain-specific chatbot** in the extraction series.

---

## The Full Pipeline

```
GHL API Docs Site (marketplace.gohighlevel.com/docs)
        â”‚
        â–¼
1. DISCOVER  (discover_site/)
   sitemap_utils.py â†’ sitemap XML â†’ discovered_pages.json
   smart_discover.py â†’ JS-rendered page fallback
        â”‚
        â–¼
2. CRAWL  (smart_crawler/)
   crawl4ai â†’ raw scraped markdown
   data_processing.py â†’ structured *_SUMMARY.txt
   outputs/pages/
     â”œâ”€â”€ *.md          (raw API docs â€” ~707 files)
     â””â”€â”€ *_SUMMARY.txt (structured metadata â€” ~707 files)
        â”‚
        â–¼
3. BUILD MASTER INDEX  (utils/)
   master_index_generator_v2.py â†’ GHL_API_MASTER_INDEX_V2.txt
   (aggregates all endpoints by category â€” the "list all" answer)
        â”‚
        â–¼
4. UPLOAD  (utils/)
   upload_all_ghl_docs.py      â†’ ~1414 files â†’ File Search Store
   upload_master_index_v2.py   â†’ master index â†’ same store
   ghl_store_name.txt          â†’ persisted store resource path
        â”‚
        â–¼
5. QUERY  (root/)
   ghl_chatbot_streamlit.py    â†’ Split-panel Streamlit UI
   ghl_chatbot_streamlit-1.py  â†’ Standard chat Streamlit UI (v1)
   utils/ghl_chatbot_cli.py    â†’ Interactive CLI mode
```

---

## File Structure

```
crawl4ai-exp-project-v1/
â”œâ”€â”€ ghl_chatbot_streamlit.py        â† v2 UI (split panel â€” main)
â”œâ”€â”€ ghl_chatbot_streamlit-1.py      â† v1 UI (sidebar + chat)
â”œâ”€â”€ ghl_store_name.txt              â† persisted File Search store ID
â”œâ”€â”€ discover_site/
â”‚   â”œâ”€â”€ sitemap_utils.py            â† XML sitemap parser
â”‚   â”œâ”€â”€ discover.py                 â† main discovery runner
â”‚   â””â”€â”€ smart_discover.py           â† JS fallback
â”œâ”€â”€ smart_crawler/
â”‚   â”œâ”€â”€ crawler.py                  â† crawl4ai async crawler
â”‚   â”œâ”€â”€ data_processing.py          â† LangChain + LLM summarizer
â”‚   â””â”€â”€ schema.py                   â† Pydantic output models
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ create_ghl_store.py         â† create File Search store
â”‚   â”œâ”€â”€ upload_all_ghl_docs.py      â† batch upload 1414 files
â”‚   â”œâ”€â”€ upload_master_index.py      â† upload master index v1
â”‚   â”œâ”€â”€ upload_master_index_v2.py   â† upload master index v2
â”‚   â”œâ”€â”€ master_index_generator.py   â† build master index v1 (LLM-parsed)
â”‚   â”œâ”€â”€ master_index_generator_v2.pyâ† build master index v2 (filename-based)
â”‚   â”œâ”€â”€ cleanup_master_index.py     â† fix category explosion from v1
â”‚   â”œâ”€â”€ delete_old_master_index.py  â† targeted store document deletion
â”‚   â”œâ”€â”€ check_ghl_store.py          â† inspect store contents
â”‚   â”œâ”€â”€ ghl_chatbot_cli.py          â† CLI query interface
â”‚   â”œâ”€â”€ test_api_connection.py      â† API health check
â”‚   â””â”€â”€ test_single_upload.py       â† upload smoke test
â””â”€â”€ outputs/
    â””â”€â”€ pages/
        â”œâ”€â”€ *.md                    â† raw crawled docs (707 files)
        â”œâ”€â”€ *_SUMMARY.txt           â† structured summaries (707 files)
        â”œâ”€â”€ GHL_API_MASTER_INDEX_SUMMARY.txt   â† v1 (raw LLM output)
        â”œâ”€â”€ GHL_API_MASTER_INDEX_CLEAN.txt     â† v1 cleaned
        â””â”€â”€ GHL_API_MASTER_INDEX_V2.txt        â† v2 (filename-based, best)
```

---

## What's in the File Search Store

Total: **~1415 documents** in a single store named `ghl-api-v2-docs`.

| Document Type | Count | Purpose |
|--------------|-------|---------|
| `.md` files | ~707 | Full endpoint documentation (parameters, examples) |
| `_SUMMARY.txt` files | ~707 | Structured metadata (endpoint name, method, URL, auth) |
| Master Index | 1 | Aggregated reference for "list all" queries |

**Store resource path format:** `fileSearchStores/{name}-{hash}`
**Persisted in:** `ghl_store_name.txt`

---

## Scale

- **Website:** marketplace.gohighlevel.com/docs
- **~38 API categories** (Contacts, Calendars, Conversations, Payments, etc.)
- **~700 endpoints** across all categories
- **~1415 files** in the File Search store
- **Upload time:** ~20â€“30 minutes for initial batch

---

## UI Architecture

### v2 (Split Panel) â€” `ghl_chatbot_streamlit.py`
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ’¬ Chat (1/3)      â”‚  ðŸ“„ Response (2/3)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  Stats: Endpoints   â”‚  Full markdown response displayed    â”‚
â”‚         Categories  â”‚  here â€” wide reading area            â”‚
â”‚         Messages    â”‚                                       â”‚
â”‚                     â”‚                                       â”‚
â”‚  Example queries    â”‚                                       â”‚
â”‚  â†‘ clickable        â”‚                                       â”‚
â”‚                     â”‚                                       â”‚
â”‚  Chat history       â”‚                                       â”‚
â”‚  (80-char preview)  â”‚                                       â”‚
â”‚                     â”‚                                       â”‚
â”‚  [Clear Chat]       â”‚                                       â”‚
â”‚  [Chat input box]   â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
- Left panel stores history, right panel shows full response
- UI memory only â€” chat history is NOT passed to Gemini queries

### v1 (Standard Chat) â€” `ghl_chatbot_streamlit-1.py`
```
Sidebar: Quick stats + example queries + clear button
Main: Standard st.chat_message() bubbles (full response inline)
```

---

## Repo Evolution Timeline

| Date | Commit | What Changed |
|------|--------|-------------|
| May 2025 | `first scrape w/ crawl4ai` | Basic crawler prototype |
| May 2025 | `url discovery done!` | Sitemap parsing added |
| Dec 2025 | `GHL RAG bot w Google Managed RAG v1` | Full RAG pipeline (CLI chatbot) |
| Dec 2025 | `Streamlit based GHL API Doc v2 RAG bot` | Streamlit UI added |

**Key insight:** 7-month gap between crawling and RAG. The crawler became infrastructure; the RAG chatbot was the product.

---

## Dependencies

```toml
[tool.poetry.dependencies]
python = ">=3.12,<4.0"
crawl4ai = "*"
playwright = "*"
python-dotenv = "*"
beautifulsoup4 = "*"
requests = "*"
google-genai = "^1.55.0"   # File Search API
streamlit = "^1.52.2"
```

Notable: No LangChain in the final chatbot (only in the earlier crawler pipeline). The RAG layer is entirely Google-native.

---

## Auth / Config

```
GEMINI_API_KEY    â† single env var (API key mode, not Vertex AI)
ghl_store_name.txt â† persisted store resource path
```

No GOOGLE_GENAI_USE_VERTEXAI toggle used here â€” this is personal/dev mode throughout (API key only).
